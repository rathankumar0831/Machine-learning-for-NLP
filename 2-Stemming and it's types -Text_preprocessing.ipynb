{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162942d0-caa7-434e-89c1-8f25404f7837",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3fb348-a5b9-4007-aecd-02c504582081",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification problem\n",
    "### Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb04931-593e-462d-99cb-80fd49e584cd",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fdc6a67-d96e-47c1-b7d8-579b8d27c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalized----->final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    print(word+'----->'+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee226546-a945-4bfe-a815-1e9f7d1308d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de60d529-41a3-4fcb-ad69-84ddeb246c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laugh'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('laughing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a25a83-36b5-4829-8bff-52fe3074bd99",
   "metadata": {},
   "source": [
    "## RegexpStemmer class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50126840-14fd-478d-921c-06cc1bfcac7b",
   "metadata": {},
   "source": [
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4cab898-c553-4005-94a5-551892c4e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af35aa26-e392-4b74-95c8-cf71ae4d67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73d0e5ed-2fb0-4e15-a143-33318a88ef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e90758b1-e2fe-406a-8594-62d92496784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f33393-f21b-46e2-ac75-731f4fd2e270",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae029af-411b-4e0f-ba68-729d5a8cd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "121cd6f6-6df6-4e59-9bb0-75a525cdd7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalized----->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'----->'+snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daf48a72-ce10-46e5-8a59-cf0ecefbc70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9befa61a-62da-43c2-8d19-68238936420c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ad1dc50-ba60-4fde-bc1d-4a891ad59dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d01edee7-f9b3-4256-903a-05d4aa3ba70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porterstemmer\n",
    "stemming.stem('fairly'), stemming.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6bb225d-329b-404c-b41c-439c9dff613b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#snowballstemmer\n",
    "snowballstemmer.stem('fairly'), snowballstemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d517cd-baad-4b46-b519-764ef857b032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
